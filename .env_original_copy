# ==========================================
# Environment-specific logging configuration
# ==========================================
LOG_DIR="../logs"
LOG_FILE_MAX_BYTES=524288
LOG_FILE_BACKUP_COUNT=30
# ==========================================
# RAW Data Ingestion Settings
# ==========================================
RAW_DATA_FILE_NAME="stud.csv"
RAW_DATA_DIRECTORY="../../notebook/data"
RAW_DATA_PATH="${RAW_DATA_DIRECTORY}/${RAW_DATA_FILE_NAME}"
# ==========================================
# Data Ingestion Settings
# ==========================================
DATA_FILE_NAME="data.csv"
DATA_DIRECTORY="../../artifacts"
DATA_PATH="${DATA_DIRECTORY}/${DATA_FILE_NAME}"
# ==========================================
INPUT_FEATURE_FILE_NAME="X.csv"
INPUT_FEATURE_DIRECTORY="../../artifacts"
INPUT_FEATURE_PATH="${INPUT_FEATURE_DIRECTORY}/${INPUT_FEATURE_FILE_NAME}"
# ==========================================
TARGET_FEATURE_FILE_NAME="y.csv"
TARGET_FEATURE_DIRECTORY="../../artifacts"
TARGET_FEATURE_PATH="${TARGET_FEATURE_DIRECTORY}/${TARGET_FEATURE_FILE_NAME}"

X_TRAIN_FILE_NAME="X_train.csv"
X_TRAIN_DIRECTORY="../../artifacts"
X_TRAIN_DATA_PATH="${X_TRAIN_DIRECTORY}/${X_TRAIN_FILE_NAME}"

y_TRAIN_FILE_NAME="y_train.csv"
y_TRAIN_DIRECTORY="../../artifacts"
y_TRAIN_DATA_PATH="${y_TRAIN_DIRECTORY}/${y_TRAIN_FILE_NAME}"

X_VAL_FILE_NAME="X_val.csv"
X_VAL_DIRECTORY="../../artifacts"
X_VAL_DATA_PATH="${X_VAL_DIRECTORY}/${X_VAL_FILE_NAME}"

y_VAL_FILE_NAME="y_val.csv"
y_VAL_DIRECTORY="../../artifacts"
y_VAL_DATA_PATH="${y_VAL_DIRECTORY}/${y_VAL_FILE_NAME}"

X_TEST_FILE_NAME="X_test.csv"
X_TEST_DIRECTORY="../../artifacts"
X_TEST_DATA_PATH="${X_TEST_DIRECTORY}/${X_TEST_FILE_NAME}"

y_TEST_FILE_NAME="y_test.csv"
y_TEST_DIRECTORY="../../artifacts"
y_TEST_DATA_PATH="${y_TEST_DIRECTORY}/${y_TEST_FILE_NAME}"

# ==========================================
# Target Column for Prediction
# ==========================================
TARGET_COLUMN="math_score"
# ==========================================
# TRAIN Data Ingestion Settings
# ==========================================
TRAIN_DATA_FILE_NAME="train.csv"
TRAIN_DATA_DIRECTORY="../../artifacts"
TRAIN_DATA_FILE="${TRAIN_DATA_DIRECTORY}/${TRAIN_DATA_FILE_NAME}"
# ==========================================
# TEST Data Ingestion Settings
# ==========================================
TEST_DATA_FILE_NAME="test.csv"
TEST_DATA_DIRECTORY="../../artifacts"
TEST_DATA_FILE="${TEST_DATA_DIRECTORY}/${TEST_DATA_FILE_NAME}"
# =========================================
# Data Transformation Settings - Preprocessor
# ==========================================
TRANSFORMED_TRAIN_FILE_NAME="transformed_train.csv"
TRANSFORMED_TRAIN_DIRECTORY="../../artifacts"
TRANSFORMED_TRAIN_FILE="${TRANSFORMED_TRAIN_DIRECTORY}/${TRANSFORMED_TRAIN_FILE_NAME}"
# ==========================================
TRANSFORMED_TEST_FILE_NAME="transformed_test.csv"
TRANSFORMED_TEST_DIRECTORY="../../artifacts"
TRANSFORMED_TEST_FILE="${TRANSFORMED_TEST_DIRECTORY}/${TRANSFORMED_TEST_FILE_NAME}"
# ==========================================
# DATA SPLIT RATIO and RANDOM STATE
# ==========================================
TEST_SIZE=0.2
TEST_SIZE_VAL=0.25
RANDOM_STATE=42
# ==========================================
# LLM & API PROVIDERS
# ==========================================
OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-ant-..."
GOOGLE_PALM_API_KEY="your-google-key"
HUGGINGFACE_TOKEN="hf_..."
COHERE_API_KEY="your-cohere-key"

# ==========================================
# VECTOR DATABASE SETTINGS (RAG)
# ==========================================
PINECONE_API_KEY="your-pinecone-key"
PINECONE_ENVIRONMENT="us-east-1-aws"
CHROMA_DB_PATH="./data/chroma_db"
MILVUS_HOST="localhost"
MILVUS_PORT="19530"

# ==========================================
# MODEL CONFIGURATION
# ==========================================
DEFAULT_MODEL_NAME="gpt-4o"
EMBEDDING_MODEL="text-embedding-3-small"
TEMPERATURE=0.7
MAX_TOKENS=2048

# ==========================================
# DATABASE & INFRASTRUCTURE
# ==========================================
# For tracking experiments or storing metadata
DATABASE_URL="postgresql://user:password@localhost:5432/ai_db"
REDIS_URL="redis://localhost:6379/0"

# ==========================================
# MLOPS & OBSERVABILITY
# ==========================================
# For logging runs to Weights & Biases or LangSmith
WANDB_API_KEY="your-wandb-key"
WANDB_PROJECT="my-ai-project"
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_API_KEY="ls__..."

# ==========================================
# CLOUD STORAGE (S3/Azure/GCP)
# ==========================================
# For storing large datasets or model weights
AWS_ACCESS_KEY_ID="your-access-key"
AWS_SECRET_ACCESS_KEY="your-secret-key"
AWS_REGION="us-east-1"
S3_BUCKET_NAME="my-ml-datasets"